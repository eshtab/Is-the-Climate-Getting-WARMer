{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import csv\n",
    "import calendar\n",
    "\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "\n",
    "import os,sys,inspect\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir) \n",
    "from environmentVariables import environment_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate=pd.read_excel(user_key['observed_raw_unclean']+'climate-daily-weatherstats.xlsx',sheet_name=1)\n",
    "power=pd.read_csv(user_key['observed_raw_unclean']+'POWER-airportlocation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all columns in climate except for, \n",
    "#Date, precipitation, avg_hourly_pressure_station,All Sky Surface Longwave Downward Irradiance\n",
    "#ALLSKY_SFC_LW_DWN, avg_hourly_wind_speed,max_wind_speed, avg_hourly_temperature, max_temperature, min_temperature\n",
    "\n",
    "climate_new = pd.DataFrame()\n",
    "climate_new['Date'] = climate['date']\n",
    "climate_new['precipitation'] = climate['precipitation']\n",
    "climate_new['avg_hourly_pressure_station'] = climate['avg_hourly_pressure_station']\n",
    "climate_new['avg_hourly_wind_speed'] = climate['avg_hourly_wind_speed']\n",
    "climate_new['max_wind_speed'] = climate['max_wind_speed']\n",
    "climate_new['avg_hourly_temperature'] = climate['avg_hourly_temperature']\n",
    "climate_new['max_temperature'] = climate['max_temperature']\n",
    "climate_new['min_temperature'] = climate['min_temperature']\n",
    "\n",
    "\n",
    "\n",
    "power_new = pd.DataFrame()\n",
    "power_new['Date'] = pd.to_datetime((power.YEAR*10000+power.MO*100+power.DY).apply(str),format='%Y%m%d')\n",
    "power_new['ALLSKY_SFC_LW_DWN'] = power['ALLSKY_SFC_LW_DWN']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#power_new.ALLSKY_SFC_LW_DWN.count(-999)\n",
    "power_new.eq(0).sum()\n",
    "power_new.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_new.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we delete leap year columns\n",
    "\n",
    "climate_new = climate_new[~((climate_new.Date.dt.month == 2) & (climate_new.Date.dt.day == 29))]\n",
    "\n",
    "power_new = power_new[~((power_new.Date.dt.month == 2) & (power_new.Date.dt.day == 29))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the dates\n",
    "\n",
    "climate_new = climate_new.sort_values(by=\"Date\")\n",
    "power_new = power_new.sort_values(by=\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_new.to_csv(user_key['observed_raw_clean']+'climate-daily-weatherstats_Cleaned.csv', index=None)\n",
    "power_new.to_csv(user_key['observed_raw_clean']+'POWER-airportlocation_Cleaned.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1.csv_data_extraction_CRCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import netCDF4\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import csv\n",
    "import calendar\n",
    "\n",
    "import os,sys,inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir) \n",
    "from environmentVariables import environment_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files\n",
    "\n",
    "data=pd.read_csv(user_key['path_in']+'tasmin/tasmin_20010101-20051231.csv', header=None)\n",
    "data_time = pd.read_csv(user_key['path_in']+'tasmin/time_20010101-20051231.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data))\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first position for toronto\n",
    "var = data.iloc[119, 211] \n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate num of leap years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input list initialization\n",
    "input_list = [1950, 1951, 1952, 1953, 1954, 1955,\n",
    "         1956, 1957, 1958, 1959, 1960,\n",
    "         1961, 1962, 1963, 1964, 1965, \n",
    "         1966, 1967, 1968, 1969, 1970, \n",
    "         1971, 1972, 1973, 1974, 1975, \n",
    "         1976, 1977, 1978, 1979, 1980, \n",
    "         1981, 1982, 1983, 1984, 1985\n",
    "        ,1986, 1987, 1988, 1989, 1990\n",
    "        ,1991, 1992, 1993, 1994, 1995\n",
    "        ,1996, 1997, 1998, 1999, 2000\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLeapYear(input_list):\n",
    "    ans = 0\n",
    "    for elem in input_list:\n",
    "        if calendar.isleap(int(elem)):\n",
    "            ans = ans + 1\n",
    "    return ans\n",
    "\n",
    "numleap = findLeapYear(input_list)\n",
    "print(numleap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract based on rlat and rlon\n",
    "\n",
    "rlon_x = 211 # adjusted from 212 since headers start at 0\n",
    "rlat_y = 119 # adjusted from 120 since index starts at 0\n",
    "counter = 0\n",
    "\n",
    "list_of_vars = []\n",
    "\n",
    " \n",
    "while (rlat_y+counter) < len(data)-1:\n",
    "    var = data.iloc[rlat_y+counter, rlon_x]\n",
    "    list_of_vars.append(var)\n",
    "        \n",
    "    counter+=260 \n",
    "\n",
    "len(list_of_vars) #should always be 1825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data_time and transpose into column and append variable and date info to new df\n",
    "data_all = data_time.transpose()\n",
    "data_all.insert(1, 'Variable', list_of_vars)\n",
    "data_all = data_all.rename(columns={0: 'Date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change time units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startdate = \"12/01/1949\"\n",
    "temp = pd.to_datetime(startdate) + pd.DateOffset(days= 13171.5 +numleap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change time units from 'days since 12/01/1949' to actual date\n",
    "startdate = \"12/01/1949\"\n",
    "row_iterator = data_all.iterrows()\n",
    "counter = 1\n",
    "\n",
    "for i, row in row_iterator:\n",
    "    if counter != len(data_all)+1:\n",
    "        #temp = pd.to_datetime(startdate) + pd.DateOffset(days=data_all.at[i, 'Date']+9)\n",
    "        #if temp.month != 2 and temp.day != 29:\n",
    "            #data_all.at[i, 'Date_new'] = pd.to_datetime(temp)\n",
    "        data_all.at[i, 'Date_new'] = pd.to_datetime(startdate) + \\\n",
    "                                     pd.DateOffset(days=data_all.at[i, 'Date']+numleap)\n",
    "            #data_all.at[i, 'Date_new2'] = pd.to_datetime(data_all.at[i, 'Date_new']) + pd.DateOffset(days=9)\n",
    "            \n",
    "    counter += 1\n",
    "\n",
    "data_all['Date_new'] = pd.to_datetime(data_all['Date_new']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag leap years\n",
    "\n",
    "row_iterator = data_all.iterrows()\n",
    "counter = 1\n",
    "\n",
    "for i, row in row_iterator:\n",
    "    if counter != len(data_all)+1:\n",
    "        if data_all.at[i, 'Date_new'].month == 2 and data_all.at[i, 'Date_new'].day == 29:\n",
    "             data_all.at[i, 'flag'] = 'flag'\n",
    "\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if flag, change flagged date to +1\n",
    "\n",
    "row_iterator = data_all.iterrows()\n",
    "counter2 = 1\n",
    "\n",
    "for i, row in row_iterator:\n",
    "    if counter2 != len(data_all)+1:\n",
    "        if data_all.at[i, 'flag'] == 'flag':\n",
    "            data_all.at[i, 'Date_2'] = data_all.at[i+1, 'Date_new']\n",
    "    counter2+=1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy over date from before if Date_2 is null \n",
    "# otherwise keep the value in Date_2\n",
    "\n",
    "row_iterator = data_all.iterrows()\n",
    "counter3 = 1\n",
    "numberofflags = 0\n",
    "\n",
    "for i, row in row_iterator:\n",
    "    if counter3 != len(data_all)+1:\n",
    "        if data_all.at[i, 'flag'] == 'flag':\n",
    "            numberofflags+=1\n",
    "        temp = data_all.at[i, 'Date_new'] + pd.DateOffset(days=numberofflags)\n",
    "        if (temp.month == 2 and temp.day == 29):\n",
    "            data_all.at[i, 'Date_2'] = data_all.at[i, 'Date_new'] + pd.DateOffset(days=numberofflags+1)\n",
    "        else:\n",
    "            data_all.at[i, 'Date_2'] = data_all.at[i, 'Date_new'] + pd.DateOffset(days=numberofflags)\n",
    "\n",
    "\n",
    "    counter3+=1\n",
    "\n",
    "data_all['Date_2'] = pd.to_datetime(data_all['Date_2']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete unnecessary columns\n",
    "del data_all['Date']\n",
    "del data_all['Date_new']\n",
    "del data_all['flag']\n",
    "\n",
    "# rename column\n",
    "data_all = data_all.rename(columns={'Date_2': 'Date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder column\n",
    "data_all = data_all[['Date', 'Variable']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all.to_csv(user_key['model_raw_unclean']+'tasmin/tasmin_extrTO_2001-2005.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all.to_csv(user_key['model_raw_unclean']+'tasmin/tasmin_extrTO_2001-2005.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import csv\n",
    "import calendar\n",
    "\n",
    "import os,sys,inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir) \n",
    "from environmentVariables import environment_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files\n",
    "\n",
    "data_one=pd.read_csv(user_key['model_raw_unclean']+'pr/pr_extrTO_1986-1990.csv')\n",
    "data_two=pd.read_csv(user_key['model_raw_unclean']+'pr/pr_extrTO_1991-1995.csv')\n",
    "data_three=pd.read_csv(user_key['model_raw_unclean']+'pr/pr_extrTO_1996-2000.csv')\n",
    "data_four=pd.read_csv(user_key['model_raw_unclean']+'pr/pr_extrTO_2001-2005.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE\n",
    "frames = [data_one, data_two, data_three, data_four]\n",
    "result = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(user_key['model_raw_clean']+'pr/pr_all_extrTO_1986-2005.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step3.5_dq_fillin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import csv\n",
    "import calendar\n",
    "\n",
    "import os,sys,inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir) \n",
    "from environmentVariables import environment_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file created by step 3\n",
    "data=pd.read_csv(user_key['observed_raw_clean']+'climate-daily-weatherstats_Cleaned.csv')\n",
    "\n",
    "# read fill in data observed data\n",
    "dataFillIn=pd.read_csv(user_key['observed_raw_clean']+'DQ Report/projectedvsobserved_fillin.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the data file, if the precipitation is null then \n",
    "# look through the fill in file if it has that date, if so fill in the value from fill in to the data\n",
    "\n",
    "# make the date column the index for searching \n",
    "dataFillIn.set_index('Date',inplace = True)\n",
    "\n",
    "row_iterator = data.iterrows()   \n",
    "for i, row in row_iterator:\n",
    "    if (pd.isnull(data.at[i,\"precipitation\"])):\n",
    "        print(data.at[i,\"Date\"])\n",
    "       # print(dataFillIn.index.values)\n",
    "        #if null then replace with variable from fill in\n",
    "        data.at[i,\"precipitation\"] = dataFillIn.loc[data.at[i,\"Date\"],\"precipitation\"]\n",
    "        print(dataFillIn.loc[data.at[i,\"Date\"],\"precipitation\"])\n",
    "        \n",
    "        \n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to file\n",
    "data.to_csv(user_key['observed_raw_clean']+'climate-daily-weatherstats_Cleaned.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step3.Unit_Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import csv\n",
    "import calendar\n",
    "\n",
    "import os,sys,inspect\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir) \n",
    "from environmentVariables import environment_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files\n",
    "data=pd.read_csv(user_key['model_raw_clean']+'pr/pr_all_extrTO_1986-2005.csv')\n",
    "\n",
    "# conversion equation based on variable name\n",
    "variableName = \"pr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# loop through the rows creating a new converted column    \n",
    "row_iterator = data.iterrows()   \n",
    "for i, row in row_iterator:\n",
    "    currVar = (data.at[i,'Variable'])\n",
    "    if (currVar != \"Variable\" ):\n",
    "        if (variableName == \"pr\"):\n",
    "            #1 kg/m2/s = 86400 mm/day\n",
    "            data.at[i, 'Variable_converted'] = (float(currVar) *  (86400))\n",
    "        elif (variableName == \"ps\"):\n",
    "            #1 pa\t0.001 kP\n",
    "             data.at[i, 'Variable_converted'] = (float(currVar) *  (0.001))\n",
    "        elif (variableName == \"rlds\"):\n",
    "            data.at[i, 'Variable_converted'] = (float(currVar))\n",
    "        elif (variableName == \"sfcWind\"):\n",
    "            #1 m/s\t3.6km/h\n",
    "            data.at[i, 'Variable_converted'] = (float(currVar) *  (3.6))\n",
    "        elif (variableName == \"sfcWindmax\"):\n",
    "            #1 m/s\t3.6km/h\n",
    "            data.at[i, 'Variable_converted'] = (float(currVar) *  (3.6))\n",
    "        elif (variableName == \"tas\"):\n",
    "            # 1K = -273 degrees celsius\n",
    "            data.at[i, 'Variable_converted'] = (float(currVar) - (273.15))\n",
    "        elif (variableName == \"tasmax\"):\n",
    "            # 1K = -273 degrees celsius\n",
    "            data.at[i, 'Variable_converted'] = (float(currVar) - (273.15))\n",
    "        elif (variableName == \"tasmin\"):\n",
    "            # 1K = -273 degrees celsius\n",
    "            data.at[i, 'Variable_converted'] = (float(currVar) - (273.15))\n",
    "                                  \n",
    "        \n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete unnecessary columns\n",
    "del data['Variable']\n",
    "\n",
    "# rename column\n",
    "data = data.rename(columns={'Variable_converted': 'Variable'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(user_key['model_raw_clean']+'pr/pr_allCONV_extrTO_1986-2005.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step4.mapping_model_to_observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import csv\n",
    "import calendar\n",
    "\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "\n",
    "import os,sys,inspect\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir) \n",
    "from environmentVariables import environment_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#variable (change to read user input)\n",
    "variable = 'pr'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use inputs to select file for climate model\n",
    "\n",
    "# need to figure out the time \n",
    "\n",
    "data=pd.read_csv(user_key['model_raw_clean']+variable+'/'+variable+'_allCONV_extrTO_1986-2005.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read observational climate csv\n",
    "\n",
    "if variable =='rlds':\n",
    "    observeData=pd.read_csv(user_key['observed_raw_clean']+'POWER-airportlocation_Cleaned.csv')\n",
    "else:\n",
    "    observeData=pd.read_csv(user_key['observed_raw_clean']+'climate-daily-weatherstats_Cleaned.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date'] =  pd.to_datetime(data['Date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read column based on the variable \n",
    "\n",
    " \n",
    "if variable == 'tas':\n",
    "            #then it is TEMP in the data, find the column\n",
    "    column = 'avg_hourly_temperature'\n",
    "    \n",
    "elif variable == 'pr' :\n",
    "    column = 'precipitation'\n",
    "            \n",
    "elif variable == 'ps' :\n",
    "    column = 'avg_hourly_pressure_station'\n",
    "            \n",
    "elif variable == 'sfcWind' :\n",
    "    column = 'avg_hourly_wind_speed'\n",
    "            \n",
    "elif variable == 'sfcWindmax' :\n",
    "    column = 'max_wind_speed'\n",
    "            \n",
    "elif variable == 'tasmax' :\n",
    "    column = 'max_temperature'\n",
    "            \n",
    "elif variable == 'tasmin' :\n",
    "    column = 'min_temperature'\n",
    "\n",
    "elif variable == 'rlds':\n",
    "    column = 'ALLSKY_SFC_LW_DWN'\n",
    "          \n",
    "\n",
    "row_iterator = observeData.iterrows()\n",
    "counter =0\n",
    "\n",
    "dates = []\n",
    "observedData = []\n",
    "modelData = []\n",
    "\n",
    "#the for loop will loop through the observed data file (weatherstats)\n",
    "for i, row in row_iterator:\n",
    "        if counter != len(observeData):\n",
    "            dates.append(observeData.at[i,'Date'])\n",
    "            observedData.append(observeData.at[i,column])\n",
    "            counter += 1\n",
    "\n",
    "row_ittr2 = data.iterrows()\n",
    "counter =0\n",
    "#the for loop will loop through the model data file \n",
    "for i, row in row_ittr2:\n",
    "         if counter != len(data):\n",
    "            modelData.append(data.at[i,'Variable'])\n",
    "            counter += 1\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "#now we have all the variables in array now we create a dataframe\n",
    "data_all = pd.DataFrame()\n",
    "data_all.insert(0, 'Date', dates)\n",
    "data_all.insert(1, 'Observed'+variable, observedData)\n",
    "data_all.insert(2, 'Model'+variable, modelData)\n",
    "        \n",
    "print(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all.to_csv(user_key['projectedvsobserved_mapped']+ variable+'_comparison_output.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step5.biascalc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import csv\n",
    "import calendar\n",
    "\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "\n",
    "import os,sys,inspect\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir) \n",
    "from environmentVariables import environment_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['pr','ps','rlds','sfcWind','sfcWindmax','tas','tasmax','tasmin']\n",
    "\n",
    "for variable in variables:\n",
    "    data=pd.read_csv(user_key['projectedvsobserved_mapped']+ variable+'_comparison_output.csv')\n",
    "\n",
    "    biasData = data['Model'+variable] - data['Observed'+variable]\n",
    "\n",
    "    data[\"Bias\"] = biasData\n",
    "    data.to_csv(user_key['projectedvsobservedbias_mapped']+ variable+'_comparison_bias_output.csv', index=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

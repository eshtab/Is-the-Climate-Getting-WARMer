{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import calendar\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import dash\n",
    "import dash_table\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import datetime as dt\n",
    "\n",
    "import os,sys,inspect\n",
    "from dash.dependencies import Input, Output, State\n",
    "\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir) \n",
    "from environmentVariables import environment_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_key=environment_variables['eshta']\n",
    "pd.set_option('display.precision', 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(user_key['extremes_raw_unclean']+'weatherstats_toronto_normals_daily-1990-2020.csv')\n",
    "data2= pd.read_csv(user_key['extremes_raw_unclean']+'weatherstats-toronto-daily-1990-2020.csv')\n",
    "data3= pd.read_csv(user_key['extremes_raw_unclean']+'weatherstats_toronto_normals_monthly-1990-2020.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables to keep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep\n",
    "# date\n",
    "# max_temperature\n",
    "# avg_hourly_temperature\n",
    "# min_temperature\n",
    "# max_humidex\n",
    "# min_windchill\n",
    "# max_relative_humidity\n",
    "# avg_hourly_relative_humidity\n",
    "# min_relative_humidity\n",
    "# max_wind_speed\n",
    "# avg_hourly_wind_speed\n",
    "# min_wind_speed\n",
    "# max_pressure_sea\n",
    "# avg_hourly_pressure_sea\n",
    "# min_pressure_sea\n",
    "# max_pressure_station\n",
    "# avg_hourly_pressure_station\n",
    "# min_pressure_station\n",
    "# max_visibility\n",
    "# avg_hourly_visibility\n",
    "# min_visibility\n",
    "# heatdegdays\n",
    "# cooldegdays\n",
    "# precipitation\n",
    "# rain\n",
    "# snow\n",
    "# snow_on_ground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new dfs for each extremes task (based on daily observed, daily normals & monthly normals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dfs\n",
    "daily_normal = pd.DataFrame()\n",
    "daily_observed = pd.DataFrame()\n",
    "monthly_normals = pd.DataFrame()\n",
    "daily_observed_mapped_version = pd.DataFrame()\n",
    "daily_observed_user_defined = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns from excel daily normal to new df (daily normals)\n",
    "\n",
    "daily_normal['date']= pd.to_datetime(data['date'])\n",
    "daily_normal['max_temperature']= data['max_temperature_v']\n",
    "daily_normal['min_temperature']= data['min_temperature_v']\n",
    "daily_normal['max_relative_humidity']= data['max_relative_humidity_v']\n",
    "daily_normal['min_relative_humidity']= data['min_relative_humidity_v']\n",
    "daily_normal['max_wind_speed']= data['max_wind_speed_v']\n",
    "daily_normal['min_wind_speed']= data['min_wind_speed_v']\n",
    "daily_normal['precipitation']= data['precipitation_v']\n",
    "daily_normal['rain']= data['rain_v']\n",
    "daily_normal['snow']= data['snow_v']\n",
    "daily_normal['snow_on_ground']= data['snow_on_ground_v']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns from excel daily normal to new df (daily observed)\n",
    "\n",
    "daily_observed['date']= pd.to_datetime(data2['date'])\n",
    "daily_observed['avg_hourly_temperature']= data2['avg_hourly_temperature']\n",
    "daily_observed['max_temperature']= data2['max_temperature']\n",
    "daily_observed['min_temperature']= data2['min_temperature']\n",
    "daily_observed['max_humidex']= data2['max_humidex']\n",
    "daily_observed['min_windchill']= data2['min_windchill']\n",
    "daily_observed['max_relative_humidity']= data2['max_relative_humidity']\n",
    "daily_observed['avg_hourly_relative_humidity']= data2['avg_hourly_relative_humidity']\n",
    "daily_observed['min_relative_humidity']= data2['min_relative_humidity']\n",
    "daily_observed['max_wind_speed']= data2['max_wind_speed']\n",
    "daily_observed['avg_hourly_wind_speed']= data2['avg_hourly_wind_speed']\n",
    "daily_observed['min_wind_speed']= data2['min_wind_speed']\n",
    "daily_observed['max_pressure_sea']= data2['max_pressure_sea']\n",
    "daily_observed['avg_hourly_pressure_sea']= data2['avg_hourly_pressure_sea']\n",
    "daily_observed['min_pressure_sea']= data2['min_pressure_sea']\n",
    "daily_observed['max_pressure_station']= data2['max_pressure_station']\n",
    "daily_observed['avg_hourly_pressure_station']= data2['avg_hourly_pressure_station']\n",
    "daily_observed['min_pressure_station']= data2['min_pressure_station']\n",
    "daily_observed['max_visibility']= data2['max_visibility']\n",
    "daily_observed['avg_hourly_visibility']= data2['avg_hourly_visibility']\n",
    "daily_observed['min_visibility']= data2['min_visibility']\n",
    "daily_observed['cooldegdays']= data2['cooldegdays']\n",
    "daily_observed['precipitation']= data2['precipitation']\n",
    "daily_observed['rain']= data2['rain']\n",
    "daily_observed['snow']= data2['snow']\n",
    "daily_observed['snow_on_ground_v']= data2['snow_on_ground']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns from excel daily normal to new df (daily observed that will be compared to daily normals)\n",
    "\n",
    "daily_observed_mapped_version['date']= pd.to_datetime(data2['date'])\n",
    "daily_observed_mapped_version['max_temperature']= data2['max_temperature']\n",
    "daily_observed_mapped_version['min_temperature']= data2['min_temperature']\n",
    "daily_observed_mapped_version['max_relative_humidity']= data2['max_relative_humidity']\n",
    "daily_observed_mapped_version['min_relative_humidity']= data2['min_relative_humidity']\n",
    "daily_observed_mapped_version['max_wind_speed']= data2['max_wind_speed']\n",
    "daily_observed_mapped_version['min_wind_speed']= data2['min_wind_speed']\n",
    "daily_observed_mapped_version['rain']= data2['rain']\n",
    "daily_observed_mapped_version['precipitation']= data2['precipitation']\n",
    "daily_observed_mapped_version['snow']= data2['snow']\n",
    "daily_observed_mapped_version['snow_on_ground_v']= data2['snow_on_ground']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns from excel daily normal to new df (daily observed that will be used for user-defined)\n",
    "\n",
    "daily_observed_user_defined['date']= pd.to_datetime(data2['date'])\n",
    "daily_observed_user_defined['avg_hourly_temperature']= data2['avg_hourly_temperature']\n",
    "daily_observed_user_defined['max_temperature']= data2['max_temperature']\n",
    "daily_observed_user_defined['min_temperature']= data2['min_temperature']\n",
    "daily_observed_user_defined['precipitation']= data2['precipitation']\n",
    "daily_observed_user_defined['avg_hourly_wind_speed']= data2['avg_hourly_wind_speed']\n",
    "daily_observed_user_defined['avg_hourly_pressure_station']= data2['avg_hourly_pressure_station']\n",
    "daily_observed_user_defined['rain']= data2['rain']\n",
    "daily_observed_user_defined['snow']= data2['snow']\n",
    "daily_observed_user_defined['snow_on_ground_v']= data2['snow_on_ground']\n",
    "daily_observed_user_defined['max_humidex']= data2['max_humidex']\n",
    "daily_observed_user_defined['min_windchill']= data2['min_windchill']\n",
    "daily_observed_user_defined['avg_hourly_relative_humidity']= data2['avg_hourly_relative_humidity']\n",
    "daily_observed_user_defined['avg_hourly_pressure_sea']= data2['avg_hourly_pressure_sea']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns from excel daily normal to new df (monthly normals)\n",
    "\n",
    "monthly_normals['date']= pd.to_datetime(data3['date'])\n",
    "monthly_normals['max_temperature']= data3['max_temperature_v']\n",
    "monthly_normals['min_temperature']= data3['min_temperature_v']\n",
    "monthly_normals['max_relative_humidity']= data3['max_relative_humidity_v']\n",
    "monthly_normals['min_relative_humidity']= data3['min_relative_humidity_v']\n",
    "monthly_normals['max_wind_speed']= data3['max_wind_speed_v']\n",
    "monthly_normals['min_wind_speed']= data3['min_wind_speed_v']\n",
    "monthly_normals['precipitation']= data3['precipitation_v']\n",
    "monthly_normals['rain']= data3['rain_v']\n",
    "monthly_normals['snow']= data3['snow_v']\n",
    "monthly_normals['snow_on_ground']= data3['snow_on_ground_v']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill 0's for blank snow on ground for summer months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_observed['month'] = daily_observed['date'].dt.month\n",
    "daily_observed_user_defined['month'] = daily_observed_user_defined['date'].dt.month\n",
    "daily_observed_mapped_version['month'] = daily_observed_mapped_version['date'].dt.month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can fill 0 for blank for snow_on_ground for all years with missing snow; \n",
    "# month must be: JUNE, JULY, AUGUST, SEPTEMBER\n",
    "# need to do for 3 dfs: daily_observed; daily_observed_user_defined; daily_observed_mapped_version\n",
    "\n",
    "\n",
    "daily_observed['flag_snow_null'] = np.where(daily_observed['snow_on_ground_v'].isnull(), 1,0)\n",
    "daily_observed['flag_summermnth_6'] = np.where(daily_observed['month'] == 6, 1, 0) \n",
    "daily_observed['flag_summermnth_7'] = np.where(daily_observed['month'] == 7, 1, 0)\n",
    "daily_observed['flag_summermnth_8'] = np.where(daily_observed['month'] == 8, 1, 0)\n",
    "daily_observed['flag_summermnth_9'] = np.where(daily_observed['month'] == 9, 1, 0)\n",
    "daily_observed['flag_total'] = daily_observed['flag_snow_null'] \\\n",
    "                                + daily_observed['flag_summermnth_6'] \\\n",
    "                                + daily_observed['flag_summermnth_7'] \\\n",
    "                                + daily_observed['flag_summermnth_8'] \\\n",
    "                                + daily_observed['flag_summermnth_9']\n",
    "\n",
    "daily_observed['snow_on_ground'] = np.where(daily_observed['flag_total']==2,0,daily_observed['snow_on_ground_v'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# can fill 0 for blank for snow_on_ground for all years with missing snow; \n",
    "# month must be: JUNE, JULY, AUGUST, SEPTEMBER\n",
    "# need to do for 3 dfs: daily_observed; daily_observed_user_defined; daily_observed_mapped_version\n",
    "\n",
    "\n",
    "daily_observed_user_defined['flag_snow_null'] = np.where(daily_observed_user_defined['snow_on_ground_v'].isnull(),1,0)\n",
    "daily_observed_user_defined['flag_summermnth_6'] = np.where(daily_observed_user_defined['month'] == 6, 1, 0) \n",
    "daily_observed_user_defined['flag_summermnth_7'] = np.where(daily_observed_user_defined['month'] == 7, 1, 0)\n",
    "daily_observed_user_defined['flag_summermnth_8'] = np.where(daily_observed_user_defined['month'] == 8, 1, 0)\n",
    "daily_observed_user_defined['flag_summermnth_9'] = np.where(daily_observed_user_defined['month'] == 9, 1, 0)\n",
    "daily_observed_user_defined['flag_total'] = daily_observed_user_defined['flag_snow_null'] \\\n",
    "                                            + daily_observed_user_defined['flag_summermnth_6'] \\\n",
    "                                            + daily_observed_user_defined['flag_summermnth_7'] \\\n",
    "                                            + daily_observed_user_defined['flag_summermnth_8'] \\\n",
    "                                            + daily_observed_user_defined['flag_summermnth_9']\n",
    "\n",
    "daily_observed_user_defined['snow_on_ground'] = np.where(daily_observed_user_defined['flag_total']==2, \\\n",
    "                                                         0, \\\n",
    "                                                         daily_observed_user_defined['snow_on_ground_v'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can fill 0 for blank for snow_on_ground for all years with missing snow; \n",
    "# month must be: JUNE, JULY, AUGUST, SEPTEMBER\n",
    "# need to do for 3 dfs: daily_observed; daily_observed_user_defined; daily_observed_mapped_version\n",
    "\n",
    "\n",
    "daily_observed_mapped_version['flag_snow_null'] = np.where(daily_observed_mapped_version['snow_on_ground_v'].isnull(), 1,0)\n",
    "daily_observed_mapped_version['flag_summermnth_6'] = np.where(daily_observed_mapped_version['month'] == 6, 1, 0) \n",
    "daily_observed_mapped_version['flag_summermnth_7'] = np.where(daily_observed_mapped_version['month'] == 7, 1, 0)\n",
    "daily_observed_mapped_version['flag_summermnth_8'] = np.where(daily_observed_mapped_version['month'] == 8, 1, 0)\n",
    "daily_observed_mapped_version['flag_summermnth_9'] = np.where(daily_observed_mapped_version['month'] == 9, 1, 0)\n",
    "daily_observed_mapped_version['flag_total'] = daily_observed_mapped_version['flag_snow_null'] \\\n",
    "                                                + daily_observed_mapped_version['flag_summermnth_6'] \\\n",
    "                                                + daily_observed_mapped_version['flag_summermnth_7'] \\\n",
    "                                                + daily_observed_mapped_version['flag_summermnth_8'] \\\n",
    "                                                + daily_observed_mapped_version['flag_summermnth_9']\n",
    "\n",
    "daily_observed_mapped_version['snow_on_ground'] = np.where(daily_observed_mapped_version['flag_total']==2, \\\n",
    "                                                           0, \\\n",
    "                                                           daily_observed['snow_on_ground_v'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete unnecessary columns from all 3 dfs\n",
    "\n",
    "del daily_observed['snow_on_ground_v']\n",
    "del daily_observed['month']\n",
    "del daily_observed['flag_snow_null']\n",
    "del daily_observed['flag_summermnth_6']\n",
    "del daily_observed['flag_summermnth_7']\n",
    "del daily_observed['flag_summermnth_8']\n",
    "del daily_observed['flag_summermnth_9']\n",
    "del daily_observed['flag_total']\n",
    "\n",
    "del daily_observed_user_defined['snow_on_ground_v']\n",
    "del daily_observed_user_defined['month']\n",
    "del daily_observed_user_defined['flag_snow_null']\n",
    "del daily_observed_user_defined['flag_summermnth_6']\n",
    "del daily_observed_user_defined['flag_summermnth_7']\n",
    "del daily_observed_user_defined['flag_summermnth_8']\n",
    "del daily_observed_user_defined['flag_summermnth_9']\n",
    "del daily_observed_user_defined['flag_total']\n",
    "\n",
    "del daily_observed_mapped_version['snow_on_ground_v']\n",
    "del daily_observed_mapped_version['month']\n",
    "del daily_observed_mapped_version['flag_snow_null']\n",
    "del daily_observed_mapped_version['flag_summermnth_6']\n",
    "del daily_observed_mapped_version['flag_summermnth_7']\n",
    "del daily_observed_mapped_version['flag_summermnth_8']\n",
    "del daily_observed_mapped_version['flag_summermnth_9']\n",
    "del daily_observed_mapped_version['flag_total']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_observed.loc[daily_observed['date'] == '1993-06-06']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_observed_user_defined.loc[daily_observed_user_defined['date'] == '1993-06-06']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_observed_mapped_version.loc[daily_observed_mapped_version['date'] == '1993-06-06']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "daily_observed.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill all other MISSING variables \n",
    "* snow on ground (for winter months)\n",
    "* snow\n",
    "* precipitation\n",
    "* rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill by finding the closest climate station with filled in data [for that date and variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read fill in data\n",
    "rainFill=pd.read_excel(user_key['extremes_raw_clean']+'DQ Reports/extremes_fillin.xlsx',sheet_name='rain')\n",
    "snowFill=pd.read_excel(user_key['extremes_raw_clean']+'DQ Reports/extremes_fillin.xlsx',sheet_name='snow')\n",
    "precipFill=pd.read_excel(user_key['extremes_raw_clean']+'DQ Reports/extremes_fillin.xlsx',sheet_name='precip')\n",
    "snowGroundFill=pd.read_excel(user_key['extremes_raw_clean']+'DQ Reports/extremes_fillin.xlsx',sheet_name='snow_on_ground')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the data file, if the precipitation is null then \n",
    "# look through the fill in file if it has that date, if so fill in the value from fill in to the data\n",
    "\n",
    "# make the date column the index for searching \n",
    "rainFill.set_index('date',inplace = True)\n",
    "snowFill.set_index('date',inplace = True)\n",
    "precipFill.set_index('Date',inplace = True)\n",
    "snowGroundFill.set_index('date',inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "#PERCIPITATION \n",
    "\n",
    "row_iterator = daily_observed.iterrows()  \n",
    "\n",
    "for i, row in row_iterator:\n",
    "    if (pd.isnull(daily_observed.at[i,\"precipitation\"])):\n",
    "        #print(daily_observed.at[i,\"date\"])\n",
    "       # print(dataFillIn.index.values)\n",
    "        #if null then replace with variable from fill in\n",
    "        daily_observed.at[i,\"precipitation\"] = precipFill.loc[daily_observed.at[i,\"date\"],\"precipitation\"]\n",
    "        #print(precipFill.loc[daily_observed.at[i,\"date\"],\"precipitation\"])\n",
    "        \n",
    "        \n",
    "row_iterator = daily_observed_mapped_version.iterrows()  \n",
    "\n",
    "for i, row in row_iterator:\n",
    "    if (pd.isnull(daily_observed_mapped_version.at[i,\"precipitation\"])):\n",
    "        #print(daily_observed_mapped_version.at[i,\"date\"])\n",
    "       # print(dataFillIn.index.values)\n",
    "        #if null then replace with variable from fill in\n",
    "        daily_observed_mapped_version.at[i,\"precipitation\"] = precipFill.loc[daily_observed_mapped_version.at[i,\"date\"],\"precipitation\"]\n",
    "       # print(precipFill.loc[daily_observed_mapped_version.at[i,\"date\"],\"precipitation\"])\n",
    "        \n",
    "\n",
    "row_iterator = daily_observed_user_defined.iterrows()  \n",
    "\n",
    "for i, row in row_iterator:\n",
    "    if (pd.isnull(daily_observed_user_defined.at[i,\"precipitation\"])):\n",
    "        #print(daily_observed_user_defined.at[i,\"date\"])\n",
    "       # print(dataFillIn.index.values)\n",
    "        #if null then replace with variable from fill in\n",
    "        daily_observed_user_defined.at[i,\"precipitation\"] = precipFill.loc[daily_observed_user_defined.at[i,\"date\"],\"precipitation\"]\n",
    "        #print(precipFill.loc[daily_observed_user_defined.at[i,\"date\"],\"precipitation\"])\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RAIN \n",
    "\n",
    "\n",
    "row_iterator = daily_observed.iterrows()  \n",
    "\n",
    "for i, row in row_iterator:\n",
    "    if (pd.isnull(daily_observed.at[i,\"rain\"])):\n",
    "        #print(daily_observed.at[i,\"date\"])\n",
    "       # print(dataFillIn.index.values)\n",
    "        #if null then replace with variable from fill in\n",
    "        daily_observed.at[i,\"rain\"] = rainFill.loc[daily_observed.at[i,\"date\"],\"rain\"]\n",
    "        #print(precipFill.loc[daily_observed.at[i,\"date\"],\"precipitation\"])\n",
    "        \n",
    "        \n",
    "row_iterator = daily_observed_mapped_version.iterrows()  \n",
    "\n",
    "for i, row in row_iterator:\n",
    "    if (pd.isnull(daily_observed_mapped_version.at[i,\"rain\"])):\n",
    "        #print(daily_observed_mapped_version.at[i,\"date\"])\n",
    "       # print(dataFillIn.index.values)\n",
    "        #if null then replace with variable from fill in\n",
    "        daily_observed_mapped_version.at[i,\"rain\"] = rainFill.loc[daily_observed_mapped_version.at[i,\"date\"],\"rain\"]\n",
    "       # print(precipFill.loc[daily_observed_mapped_version.at[i,\"date\"],\"precipitation\"])\n",
    "        \n",
    "\n",
    "row_iterator = daily_observed_user_defined.iterrows()  \n",
    "\n",
    "for i, row in row_iterator:\n",
    "    if (pd.isnull(daily_observed_user_defined.at[i,\"rain\"])):\n",
    "        #print(daily_observed_user_defined.at[i,\"date\"])\n",
    "       # print(dataFillIn.index.values)\n",
    "        #if null then replace with variable from fill in\n",
    "        daily_observed_user_defined.at[i,\"rain\"] = rainFill.loc[daily_observed_user_defined.at[i,\"date\"],\"rain\"]\n",
    "        #print(precipFill.loc[daily_observed_user_defined.at[i,\"date\"],\"precipitation\"])\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SNOW\n",
    "\n",
    "row_iterator = daily_observed.iterrows()  \n",
    "\n",
    "for i, row in row_iterator:\n",
    "    if (pd.isnull(daily_observed.at[i,\"snow\"])):\n",
    "        #print(daily_observed.at[i,\"date\"])\n",
    "       # print(dataFillIn.index.values)\n",
    "        #if null then replace with variable from fill in\n",
    "        daily_observed.at[i,\"snow\"] = snowFill.loc[daily_observed.at[i,\"date\"],\"snow\"]\n",
    "        #print(precipFill.loc[daily_observed.at[i,\"date\"],\"precipitation\"])\n",
    "        \n",
    "        \n",
    "row_iterator = daily_observed_mapped_version.iterrows()  \n",
    "\n",
    "for i, row in row_iterator:\n",
    "    if (pd.isnull(daily_observed_mapped_version.at[i,\"snow\"])):\n",
    "        #print(daily_observed_mapped_version.at[i,\"date\"])\n",
    "       # print(dataFillIn.index.values)\n",
    "        #if null then replace with variable from fill in\n",
    "        daily_observed_mapped_version.at[i,\"snow\"] = snowFill.loc[daily_observed_mapped_version.at[i,\"date\"],\"snow\"]\n",
    "       # print(precipFill.loc[daily_observed_mapped_version.at[i,\"date\"],\"precipitation\"])\n",
    "        \n",
    "\n",
    "row_iterator = daily_observed_user_defined.iterrows()  \n",
    "\n",
    "for i, row in row_iterator:\n",
    "    if (pd.isnull(daily_observed_user_defined.at[i,\"snow\"])):\n",
    "        #print(daily_observed_user_defined.at[i,\"date\"])\n",
    "       # print(dataFillIn.index.values)\n",
    "        #if null then replace with variable from fill in\n",
    "        daily_observed_user_defined.at[i,\"snow\"] = snowFill.loc[daily_observed_user_defined.at[i,\"date\"],\"snow\"]\n",
    "        #print(precipFill.loc[daily_observed_user_defined.at[i,\"date\"],\"precipitation\"])\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNOW ON THE GROUND\n",
    "\n",
    "row_iterator = daily_observed.iterrows()  \n",
    "\n",
    "for i, row in row_iterator:\n",
    "    if (pd.isnull(daily_observed.at[i,\"snow_on_ground\"])):\n",
    "        #print(daily_observed.at[i,\"date\"])\n",
    "       # print(dataFillIn.index.values)\n",
    "        #if null then replace with variable from fill in\n",
    "        daily_observed.at[i,\"snow_on_ground\"] = snowGroundFill.loc[daily_observed.at[i,\"date\"],\"snow_on_ground\"]\n",
    "        #print(precipFill.loc[daily_observed.at[i,\"date\"],\"precipitation\"])\n",
    "        \n",
    "        \n",
    "row_iterator = daily_observed_mapped_version.iterrows()  \n",
    "\n",
    "for i, row in row_iterator:\n",
    "    if (pd.isnull(daily_observed_mapped_version.at[i,\"snow_on_ground\"])):\n",
    "        #print(daily_observed_mapped_version.at[i,\"date\"])\n",
    "       # print(dataFillIn.index.values)\n",
    "        #if null then replace with variable from fill in\n",
    "        daily_observed_mapped_version.at[i,\"snow_on_ground\"] = snowGroundFill.loc[daily_observed_mapped_version.at[i,\"date\"],\"snow_on_ground\"]\n",
    "       # print(precipFill.loc[daily_observed_mapped_version.at[i,\"date\"],\"precipitation\"])\n",
    "        \n",
    "\n",
    "row_iterator = daily_observed_user_defined.iterrows()  \n",
    "\n",
    "for i, row in row_iterator:\n",
    "    if (pd.isnull(daily_observed_user_defined.at[i,\"snow_on_ground\"])):\n",
    "        #print(daily_observed_user_defined.at[i,\"date\"])\n",
    "       # print(dataFillIn.index.values)\n",
    "        #if null then replace with variable from fill in\n",
    "        daily_observed_user_defined.at[i,\"snow_on_ground\"] = snowGroundFill.loc[daily_observed_user_defined.at[i,\"date\"],\"snow_on_ground\"]\n",
    "        #print(precipFill.loc[daily_observed_user_defined.at[i,\"date\"],\"precipitation\"])\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output\n",
    "\n",
    "### For daily normals:\n",
    "* Extremes raw clean\n",
    "\n",
    "### For monthly normals:\n",
    "* Extremes raw clean\n",
    "\n",
    "### For daily observed:\n",
    "* Extremes raw clean: Daily observed extravar\n",
    "* Extremes raw clean: Daily observed (for normals comp)\n",
    "* Extremes raw clean: Daily observed (for user defined)\n",
    "* Extremes raw mapped: Daily observed (for user defined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_normal.to_csv(user_key['extremes_raw_clean']+'daily_normals_cleaned.csv', index=None)\n",
    "daily_observed.to_csv(user_key['extremes_raw_clean']+'daily_observed_cleaned_extravar.csv', index=None)\n",
    "monthly_normals.to_csv(user_key['extremes_raw_clean']+'monthly_normals_cleaned.csv', index=None)\n",
    "\n",
    "daily_observed_mapped_version.to_csv(user_key['extremes_raw_clean']+'daily_observed_cleaned_fornormalscomp.csv', index=None)\n",
    "daily_observed_user_defined.to_csv(user_key['extremes_raw_clean']+'daily_observed_cleaned_user_defined.csv', index=None)\n",
    "daily_observed_user_defined.to_csv(user_key['extremes_mapped']+'daily_observed_cleaned_user_defined.csv', index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
